---
title: "Time Series Demo"
author: "Jyotishka Datta"
date: "April 14, 2019"
output: 
  revealjs::revealjs_presentation:
    theme: serif
    highlight: haddock
    center: false
    transition: fade
    self_contained: false
    reveal_options:
      slideNumber: true
      previewLinks: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, cache = TRUE, message = F, warning = F)
rm(list = ls())
set.seed(123)
```

# Simulating Time Series 

This demo will show a few examples of simulated time series data before we explore the stan model fitting techniques. 

Here we will: 

1. Fix the values of parameters for AR or latent AR processes. 
2. Simulate sample paths or trajectories of the time series $x_t$, $y_t$. 
3. Look at the structure of the series. 


## Simulate AR(1) process

$$
x_{t} = \phi x_{t-1} + \epsilon_t, \; \epsilon_t \sim N(0, \nu)
$$


```{r, echo = T}
phi = 0.9; nu = 1; T = 500
x = numeric(T)
for(t in 1:(T-1)){
  x[t+1] = phi*x[t]+rnorm(1,0,nu)
}
```

```{r, fig.asp = 0.6}
par(mfrow=c(1,2))
plot(x, type = "l")
acf_x = acf(x, lag.max = 30, plot = F)
plot(acf_x, type ="l")
par(mfrow=c(1,1))
```

## Different $\phi$ 

Autocorrelation at lag $k$: $\gamma(k) = \phi^k$, one can see ``oscillatory" behaviour consistent with $\phi < 0$

```{r, echo = F, fig.height = 2.5, fig.width = 5}
phiset = c(0.9,-0.9,0.3)
nu = 2
T = 1000
x = matrix(0,3,T)

for (k in 1:3){
  phi = phiset[k]
  for(t in 1:(T-1)){
    x[k, t+1] = phi*x[k, t]+rnorm(1,0,nu)
  }
}

acf_data = apply(x,1, function(z) {acf(z, plot = F)$acf})

df = rbind(data.frame(values = acf_data[,1], phi = "0.9", lag = seq_along(acf_data[,1])),
           data.frame(values = acf_data[,2], phi = "-0.9", lag = seq_along(acf_data[,1])),
           data.frame(values = acf_data[,3], phi = "0.3", lag = seq_along(acf_data[,1])))

# df = rbind(df, lag = seq(1,31))

# install.packages('devtools')
# devtools::install_github('thomasp85/gganimate')

library(gganimate)
library(gifski)
library(png)
library(transformr)

ggplot(df, aes(x = lag, y = values, group = phi))+
  geom_line()+
  # Here comes the gganimate specific bits
  geom_segment(aes(xend = 31, yend = values), linetype = 2, colour = 'grey') + 
  geom_point(size = 2) + 
  geom_text(aes(x = 31.1, label = phi), hjust = 0) + 
  transition_reveal(lag) + 
  coord_cartesian(clip = 'off') + 
  labs(title = 'Autocorrelation', y = 'Lag') 
  # theme_minimal() + 
  # theme(plot.margin = margin(5.5, 40, 5.5, 5.5))
```


## Simple HMM 

$$
\begin{aligned} y_{t} &=x_{t}+\nu_{t} \\ x_{t} & \leftarrow AR(1 | \theta), \; \theta = (\phi, \nu) \end{aligned}
$$
The $\nu_t$ terms are the errors of measurement, or observation, that corrupt the signal $x_t$

```{r}
phi = 0.1; nu = 1; T = 100
x = numeric(T)
for(t in 1:(T-1)){
  x[t+1] = phi*x[t]+rnorm(1,0,nu)
}
w = 2
y = x + rnorm(T, 0, w)
```


```{r, echo = F, fig.asp = 0.6, fig.align='center'}
phi = 0.9; nu = 1; T = 200
x = numeric(T)
for(t in 1:(T-1)){
  x[t+1] = phi*x[t]+rnorm(1,0,nu)
}
w = 2
y = x + rnorm(T, 0, w)
plot(y, type = "l", main = "HMM")
lines(x, col = "blue", lwd = 2)
legend("topleft",c("y","x"), lty = 1, lwd = c(1,2), col = c(1,4))
```

## Simple Stochastic Volatility {.smaller}

Canonical SVM: 

$$
		\begin{align}
		y_t & \sim N(0, \sigma_t^2) \\
		\sigma_t & \sim \exp(\mu + x_t) \\
		x_t & \sim AR(1 \mid \theta) \; \theta = (\phi, \nu). 
		\end{align}
$$

-  Implies that conditional on $\mu, x_t$, $y_t^2 = \sigma_t^2 \kappa_t$, where $\kappa_t \sim \chi^2_1$. 
-  Take $z_t = \log(y_t^2)/2 = \log(|y_t|)$. 
-  The $z_t$ are now the new observed quantities. 

$$
		\begin{align}
		z_t & = \mu + x_t + \nu_t, \quad \text{where} \; \nu_t = \log(\kappa_t)/2\\
		x_t & \sim AR(1 \mid \theta); \; \theta = (\phi, \nu)
		\end{align}
$$



## Stochastic Volatility Path {.smaller}

```{R, echo = T}
mu = 2; 
sigma_t = exp(mu + x)
y = rnorm(T, 0, sigma_t)
```

```{r, echo =F}

par(mfrow=c(1,2))
plot(y, type ="l", main = "y")
plot(x, type ="l", col = 2, lwd = 2, main = "SVM")
lines(log(y^2)/2, col = 4, lwd = 2)
legend("topleft",c("log(|y|)","x"), lty = 1, lwd = c(2,2), col = c(2,4))
par(mfrow=c(1,1))
```


## $\log(|y_t|)$ distribution

```{r, echo =F}
hist(log(abs(y)), breaks = 25, freq = F, col = rgb(1,0,0,0.2), main ="log(|y|)")
abline(v = 0, col = "blue")
lines(density(log(abs(y))))
```


## Stan Demo: Examples 

1.  (Toy example) Mean-only Normal Shocks. 
2.  Simple AR model (stochastic unit roots)
3.  Stochastic volatility models. 

Data-sets, R and Stan Codes are available here: [https://github.com/DattaHub/sls-2019](https://github.com/DattaHub/sls-2019)

This presentation is available here (source codes are in sls-2019 repo):
[http://dattahub.github.io/sls-2019/time-series-demo.html#1](http://dattahub.github.io/sls-2019/time-series-demo.html#1)

Stan examples are taken from this Stan tutorial for time series: 
[http://tharte.github.io/mbt/mbt.html](http://tharte.github.io/mbt/mbt.html)



## Example 1

-  We'll fit a mean-only Normal "shocks" model.  

-  The data-set we'll use is the "B.2-PHAR" tab on the excel file "Time Series and Forecasting Appendix B Tables". (You don't need to open this file for fitting the model.)

-  The R code "fitting-normal-mean-only-stan.R" will read the data-set and fit the Stan model in "normal-mean-only.stan". 

- The stan code "mean-only_normal_predict_new_generated_quantities.stan" is an example of using the "generated quantities" block.

- Let us look at this stan code carefully to understand the basic functional features. 


## Example 2 and 3

-  We will use the data on US consumption and income. 
-  The R code for reading the data is "read-us-data-income.R". The same R code also calculates the residuals for regression of In
-  The Stan codes for the two models are :
   1.  "stur.stan".
   2.  "stochvol.stan"
-  The R code for fitting the two models on the same data-set is 
"analyse-us-income-stur-stochvol.R"



